{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the iris data into a DataFrame\n",
    "import pandas as pd\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data' \n",
    "## Specifying column names.\n",
    "col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris = pd.read_csv(url, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## map each iris species to a number with a dictionary and list comprehension.\n",
    "iris_class = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}\n",
    "iris['species_num'] = [iris_class[i] for i in iris.species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an 'X' matrix by dropping the irrelevant columns.\n",
    "X = iris.drop(['species', 'species_num'], axis=1)\n",
    "y = iris.species_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "## Split data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import the Classifier.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "## Instantiate the model with 5 neighbors. \n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "## Fit the model on the training data.\n",
    "knn.fit(X_train, y_train)\n",
    "## See how the model performs on the test data.\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X, Y = iris.data[:, :2], iris.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scalar.transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors= 5)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manhattan distance\n",
    "distance = tf.reduce_sum(tf.abs(tf.subtract(X_train, tf.expand_dims(X_test, 1))), axis=2)\n",
    "\n",
    "# nearest k points\n",
    "_, top_k_indices = tf.nn.top_k(tf.negative(distance), k=k)\n",
    "top_k_label = tf.gather(X_train, top_k_indices)\n",
    "\n",
    "sum_up_predictions = tf.reduce_sum(top_k_label, axis=1)\n",
    "prediction = tf.argmax(sum_up_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manhattan distance\n",
    "distance = tf.reduce_sum(tf.abs(tf.subtract(X_train, tf.expand_dims(X_test, 1))), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearest k points\n",
    "_, top_k_indices = tf.nn.top_k(tf.negative(distance), k=k)\n",
    "top_k_label = tf.gather(Y_train, top_k_indices)\n",
    "\n",
    "sum_up_predictions = tf.reduce_sum(top_k_label, axis=1)\n",
    "prediction = tf.argmax(sum_up_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5ace9456ad92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprediction_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "prediction_outcome = sess.run(prediction, feed_dict={X_train: X_train, X_test: X_test, Y_train: Y_train})\n",
    "\n",
    "# evaluation\n",
    "accuracy = 0\n",
    "for pred, actual in zip(prediction_outcome, Y_test):\n",
    "    if pred == np.argmax(actual):\n",
    "        accuracy += 1\n",
    "\n",
    "print(accuracy / len(prediction_outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "# load data\n",
    "iris = datasets.load_iris()\n",
    "x_vals = np.array([x[0:4] for x in iris.data])\n",
    "y_vals = np.array(iris.target)\n",
    "\n",
    "# one hot encoding\n",
    "y_vals = np.eye(len(set(y_vals)))[y_vals]\n",
    "\n",
    "# normalize\n",
    "x_vals = (x_vals - x_vals.min(0)) / x_vals.ptp(0)\n",
    "\n",
    "# train-test split\n",
    "np.random.seed(59)\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals) * 0.8), replace=False)\n",
    "test_indices =np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_number = len(x_vals_train[0])\n",
    "\n",
    "k = 5\n",
    "\n",
    "x_data_train = tf.placeholder(shape=[None, feature_number], dtype=tf.float32)\n",
    "y_data_train = tf.placeholder(shape=[None, len(y_vals[0])], dtype=tf.float32)\n",
    "x_data_test = tf.placeholder(shape=[None, feature_number], dtype=tf.float32)\n",
    "\n",
    "# manhattan distance\n",
    "distance = tf.reduce_sum(tf.abs(tf.subtract(x_data_train, tf.expand_dims(x_data_test, 1))), axis=2)\n",
    "\n",
    "# nearest k points\n",
    "_, top_k_indices = tf.nn.top_k(tf.negative(distance), k=k)\n",
    "top_k_label = tf.gather(y_data_train, top_k_indices)\n",
    "\n",
    "sum_up_predictions = tf.reduce_sum(top_k_label, axis=1)\n",
    "prediction = tf.argmax(sum_up_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manhattan distance\n",
    "distance = tf.reduce_sum(tf.abs(tf.subtract(x_data_train, tf.expand_dims(x_data_test, 1))), axis=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearest k points\n",
    "_, top_k_indices = tf.nn.top_k(tf.negative(distance), k=k)\n",
    "top_k_label = tf.gather(y_data_train, top_k_indices)\n",
    "\n",
    "sum_up_predictions = tf.reduce_sum(top_k_label, axis=1)\n",
    "prediction = tf.argmax(sum_up_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "prediction_outcome = sess.run(prediction, feed_dict={x_data_train: x_vals_train,\n",
    "                               x_data_test: x_vals_test,\n",
    "                               y_data_train: y_vals_train})\n",
    "\n",
    "# evaluation\n",
    "accuracy = 0\n",
    "for pred, actual in zip(prediction_outcome, y_vals_test):\n",
    "    if pred == np.argmax(actual):\n",
    "        accuracy += 1\n",
    "\n",
    "print(accuracy / len(prediction_outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
